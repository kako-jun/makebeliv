use anyhow::{Context, Result};
use clap::{Parser, Subcommand};
use std::path::PathBuf;
use std::process::Command;
use tracing::{info, warn};

#[derive(Parser)]
#[command(name = "makebeliv")]
#[command(about = "Real-time voice conversion with natural fluctuation", long_about = None)]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Setup Python environment using uv
    Setup {
        /// Skip confirmation prompts
        #[arg(short, long)]
        yes: bool,
    },

    /// Process audio file (development mode)
    Process {
        /// Input audio file
        #[arg(short, long)]
        input: PathBuf,

        /// Output audio file (default: audio/output/processed.wav)
        #[arg(short, long)]
        output: Option<PathBuf>,

        /// Voice model to use
        #[arg(short, long, default_value = "default")]
        model: String,

        /// Background noise type (cafe, street, room)
        #[arg(short, long, default_value = "cafe")]
        noise: String,

        /// Pitch shift in percentage (e.g., +3%)
        #[arg(short, long, default_value = "0")]
        pitch: f32,
    },

    /// Real-time voice conversion (future implementation)
    Monitor {
        /// Voice model to use
        #[arg(short, long, default_value = "default")]
        model: String,

        /// Background noise type
        #[arg(short, long, default_value = "cafe")]
        noise: String,

        /// Pitch shift in percentage
        #[arg(short, long, default_value = "0")]
        pitch: f32,
    },
}

fn main() -> Result<()> {
    tracing_subscriber::fmt::init();

    let cli = Cli::parse();

    match cli.command {
        Commands::Setup { yes } => setup_environment(yes),
        Commands::Process {
            input,
            output,
            model,
            noise,
            pitch,
        } => process_audio(input, output, model, noise, pitch),
        Commands::Monitor {
            model,
            noise,
            pitch,
        } => monitor_realtime(model, noise, pitch),
    }
}

fn setup_environment(skip_confirm: bool) -> Result<()> {
    info!("ğŸ”§ Makebelivç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—");

    // 1. uvãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
    info!("uvã®ç¢ºèªä¸­...");
    let uv_check = Command::new("uv").arg("--version").output();

    let uv_available = match uv_check {
        Ok(output) if output.status.success() => {
            let version = String::from_utf8_lossy(&output.stdout);
            info!("  âœ“ uv ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿: {}", version.trim());
            true
        }
        _ => {
            warn!("  âœ— uv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
            false
        }
    };

    if !uv_available {
        println!("\nğŸ“¦ uvã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:");
        println!("  curl -LsSf https://astral.sh/uv/install.sh | sh");
        println!("\nã¾ãŸã¯:");
        println!("  cargo install uv");
        println!("\nã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€å†åº¦ã“ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚");
        return Ok(());
    }

    // 2. ä»®æƒ³ç’°å¢ƒã®ä½œæˆ
    if !skip_confirm {
        println!("\nä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ (y/N)");
        let mut input = String::new();
        std::io::stdin().read_line(&mut input)?;
        if !input.trim().eq_ignore_ascii_case("y") {
            println!("ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚");
            return Ok(());
        }
    }

    info!("ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆä¸­...");
    let venv_status = Command::new("uv")
        .args(["venv", ".venv"])
        .status()
        .context("ä»®æƒ³ç’°å¢ƒã®ä½œæˆã«å¤±æ•—")?;

    if !venv_status.success() {
        anyhow::bail!("ä»®æƒ³ç’°å¢ƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ");
    }
    info!("  âœ“ ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã—ãŸ: .venv");

    // 3. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    info!("ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...");

    // PyTorchã¯CUDAå¯¾å¿œç‰ˆã‚’æ˜ç¤ºçš„ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    println!("\nğŸ” GPU (CUDA) ã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ");
    println!("  RTX 3050ãªã©ã®NVIDIA GPUã‚’ãŠæŒã¡ã®å ´åˆã¯æ¨å¥¨ã—ã¾ã™ã€‚");
    println!("  ä½¿ç”¨ã™ã‚‹å ´åˆ: y, CPUã®ã¿ã®å ´åˆ: N");

    let mut gpu_input = String::new();
    std::io::stdin().read_line(&mut gpu_input)?;
    let use_gpu = gpu_input.trim().eq_ignore_ascii_case("y");

    if use_gpu {
        info!("CUDAå¯¾å¿œPyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...");
        // CUDA 11.8å¯¾å¿œã®PyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
        let torch_install = Command::new("uv")
            .args([
                "pip",
                "install",
                "torch",
                "torchaudio",
                "--index-url",
                "https://download.pytorch.org/whl/cu118",
            ])
            .status()
            .context("PyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—")?;

        if !torch_install.success() {
            warn!("CUDAç‰ˆPyTorchã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã€‚CPUç‰ˆã‚’è©¦ã—ã¾ã™...");
        } else {
            info!("  âœ“ CUDAå¯¾å¿œPyTorchã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ");
        }
    }

    // ãã®ä»–ã®ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    let deps_status = Command::new("uv")
        .args(["pip", "install", "-r", "requirements.txt"])
        .status()
        .context("ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—")?;

    if !deps_status.success() {
        anyhow::bail!("ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ");
    }
    info!("  âœ“ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ");

    // 4. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†
    println!("\nâœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãŒå®Œäº†ã—ã¾ã—ãŸï¼");
    println!("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:");
    println!("  1. ãƒ†ã‚¹ãƒˆç”¨ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ audio/input/ ã«é…ç½®");
    println!("  2. ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ:");
    println!("     makebeliv process -i audio/input/test.wav");
    println!("\nä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–:");
    println!("  source .venv/bin/activate  # Linux/macOS");
    println!("  .venv\\Scripts\\activate     # Windows");

    Ok(())
}

fn process_audio(
    input: PathBuf,
    output: Option<PathBuf>,
    model: String,
    noise: String,
    pitch: f32,
) -> Result<()> {
    info!("ğŸ™ï¸ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ãƒ¢ãƒ¼ãƒ‰");

    if !input.exists() {
        anyhow::bail!("å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {}", input.display());
    }

    let output_path = output.unwrap_or_else(|| PathBuf::from("audio/output/processed.wav"));

    info!("è¨­å®š:");
    info!("  å…¥åŠ›: {}", input.display());
    info!("  å‡ºåŠ›: {}", output_path.display());
    info!("  ãƒ¢ãƒ‡ãƒ«: {}", model);
    info!("  ãƒã‚¤ã‚º: {}", noise);
    info!("  ãƒ”ãƒƒãƒ: {:+.1}%", pitch);

    // Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
    let python_script = "python/file_processor.py";

    let status = Command::new("python")
        .arg(python_script)
        .arg(input.to_str().unwrap())
        .status()
        .context("Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œã«å¤±æ•—")?;

    if !status.success() {
        anyhow::bail!("éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ");
    }

    info!("âœ… å‡¦ç†å®Œäº†: {}", output_path.display());

    Ok(())
}

fn monitor_realtime(model: String, noise: String, pitch: f32) -> Result<()> {
    info!("ğŸ§ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¤‰æ›ãƒ¢ãƒ¼ãƒ‰ï¼ˆæœªå®Ÿè£…ï¼‰");
    info!("è¨­å®š:");
    info!("  ãƒ¢ãƒ‡ãƒ«: {}", model);
    info!("  ãƒã‚¤ã‚º: {}", noise);
    info!("  ãƒ”ãƒƒãƒ: {:+.1}%", pitch);

    println!("\nâš ï¸  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ¼ãƒ‰ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚");
    println!("ä»£ã‚ã‚Šã«ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’ãŠè©¦ã—ãã ã•ã„:");
    println!("  makebeliv process -i audio/input/test.wav");

    Ok(())
}
